---
author: "Chao.G"
title: "ScaNN索引分享"
date: "2024-03-02"
draft: false
tags: ["ann"]
categories: ["Papers"]
---

最近在公司面向社区用户的Deep Dive直播做了有关ScaNN索引的分享 远超 IVF_FLAT、HNSW，ScaNN 索引算法赢在哪？ 这部分内容其实也已经是很老的内容了，正好趁着这次公开的分享，贴一些文字和图片出来。
ScaNN的paper在这里，[https://arxiv.org/pdf/1908.10396.pdf](https://arxiv.org/pdf/1908.10396.pdf)，代码也是开源的，[https://github.com/google-research/google-research/tree/master/scann](https://github.com/google-research/google-research/tree/master/scann)。

## IVFPQ

首先简单地介绍下IVFPQ算法的原理，因为ScaNN算法的基础是IVFPQ。
首先IVF就是通过kmeans聚类将数据分成若干个bucket，搜索时query向量和聚类中心的距离排序，选择nprobe个bucket进行计算即可。

![scann-ivf](/assets/scann-ivf.png)

PQ是一种向量压缩的手段，可以减少内存的使用。首先将向量分成m个subvector，将不同向量的相同位置的subvector做kmeans聚类，一般取256个，每个subvector就可以用1byte的聚类id表示。如果选取4维作为一个subvector，这样的压缩比就可以达到1/16。

![scann-pq1](/assets/scann-pq1.png)

![scann-pq2](/assets/scann-pq2.png)

搜索时query向量和底库向量就可以分段计算距离再求和，Distance(q_1, subvector_1) = Distance(q_1, centroid(subvector_1))，query向量和这些聚类中心的距离可以在搜索最开始预计算好，后续距离计算都可以转化成查表操作。

## ScaNN基于IVFPQ的优化

简而言之，ScaNN针对IVFPQ两点做了优化
- 量化的时候选择kmeans聚类中心来代替subvector的方式，是否有更好的方式
- 搜索时的查表操作是一个内存瓶颈的事情，是否可以更高效

### Score-aware quantization loss

友情提示：有关这部分内容只提供一个感性的认识，对于数学推导感兴趣的同学强烈建议阅读原文。
首先ScaNN针对的metric是IP（点积），定义量化loss为query和原始向量, query和量化后的向量之间的差距。$$\mathbb{E}_q \sum_{i=1}^n\left(\left\langle q, x_i\right\rangle-\left\langle q, \tilde{x}_i\right\rangle\right)^2=\mathbb{E}_q \sum_{i=1}^n\left\langle q, x_i-\tilde{x}_i\right\rangle^2$$
而离query更近的点对结果的影响更大，保证这些点的量化误差小是更重要的。 于是ScaNN提出了一种新的loss函数，这里的w表示权重， $$\ell\left(x_i, \tilde{x}_i, w\right)=\mathbb{E}_{q \sim \mathcal{Q}}\left[w\left(\left\langle q, x_i\right\rangle\right)\left\langle q, x_i-\tilde{x}_i\right\rangle^2\right]$$

![scann-loss](/assets/scann-loss.png)

由于基于IP这个metric来分析，ScaNN把量化误差分成平行分量和垂直分量以后，由于只有平行分量会对结果产生影响，所以应该施以更大的惩罚项，最后的loss function转化成如下 
$$\begin{aligned}
\ell\left(x_i, \tilde{x}_i, w\right) &=h_{\|}\left(w,\left\|x_i\right\|\right)\left\|r_{\|}\left(x_i, \tilde{x}_i\right)\right\|^2 +h_{\perp}\left(w,\left\|x_i\right\|\right)\left\|r_{\perp}\left(x_i, \tilde{x}_i\right)\right\|^2
\end{aligned}$$

![scann-loss](/assets/scann-loss2.png)

## 4bit PQ

首先回顾下PQ的计算过程，查询时预计算query和subvector的聚类中心，构建Lookup table，计算距离时通过查表拿到分段距离做加和。

![scann-fastscan](/assets/scann-fastscan1.png)

但是频繁的读内存操作还是不够高效，如果可以把Lookup table做到足够小，小到可以在寄存器里放得下，就可以把读内存的操作变成cpu高效的SIMD指令。首先每个subvector聚成16个类，这样就可以用4bit代表一个聚类中心，这也是4bit PQ名字的来源。然后将一般用float表示的距离进一步使用SQ转化成uint8，如此一来，一个subvector的Lookup table就可以使用16 * 8 = 128bit存到寄存器里。

![scann-fastscan](/assets/scann-fastscan2.png)

最后来看下寄存器的存储布局（AVX2指令集为例），将32个向量的subvector放在一个128bit的寄存器里，搭配上Lookup table，然后就可以使用SIMD shuffle一个cpu指令高效完成“查表”操作。

![scann-fastscan](/assets/scann-fastscan3.png)

![scann-fastscan](/assets/scann-fastscan4.png)

最后分享一点有趣的事情，ScaNN paper完全focus在第一点的优化上，应该说这也没什么问题，因为可以认为这是一个算法paper，着重于讲一些数学推导上。但是最后paper展示出来的实验结果实在是太惊艳了,

![scann-result](/assets/scann-result.png)

直觉上对于loss的优化不应该产生这么大的效果，也有国外的博客说明了这个问题，其实真正有用的是4bit PQ FastScan的部分，[https://medium.com/@kumon/similarity-search-scann-and-4-bit-pq-ab98766b32bd](https://medium.com/@kumon/similarity-search-scann-and-4-bit-pq-ab98766b32bd)。

## 实验结果

使用向量数据库benchmark工具 [GitHub - zilliztech/VectorDBBench: A Benchmark Tool for VectorDB](https://github.com/zilliztech/VectorDBBench)简单做了一下测试，ScaNN的性能优势还是很明显的，集成到Milvus以后，在Cohere1M数据集上QPS可以达到IVFFLAT的7倍，超过HNSW 20%左右。